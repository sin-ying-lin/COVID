{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dependent-interstate",
   "metadata": {},
   "source": [
    "# Disparities in Mental Health Service Usage during the COVID-19 Pandemic\n",
    "\n",
    "We examined the gender and racial/ethnic disapirites in mental health service usagecontrolling for internalizing problem severity with logistic regression and SMOTE sampling for unbalanced classes. \n",
    "\n",
    "We compared the predictive effects of demographic varialbes combined with four separate internalizing domains vs. one aggregated overall internalizing severity on mental health service usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharp-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pacakges\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTENC  \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.pipeline import Pipeline\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import round\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "heavy-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized preprocessing\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, numeric_features, categorical_features):\n",
    "        self.numeric_features = numeric_features\n",
    "        self.categorical_features = categorical_features\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X[self.numeric_features]\n",
    "        #Dummy code categorical varialbes \n",
    "        X_copy = X_copy.join(pd.get_dummies(X[self.categorical_features], drop_first=True)) \n",
    "        return X_copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "international-stress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customized function to create interaction terms\n",
    "class InteractionTerm(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, set1, set2):\n",
    "        self.set1 = set1\n",
    "        self.set2 = set2\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for var1 in self.set1:\n",
    "            for var2 in self.set2:\n",
    "                X_copy[var1+':'+var2] = X_copy[var1]*X_copy[var2]\n",
    "        return X_copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "entertaining-pacific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 909 entries, 0 to 908\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  909 non-null    object \n",
      " 1   age                 909 non-null    int64  \n",
      " 2   gender              909 non-null    int64  \n",
      " 3   race                909 non-null    int64  \n",
      " 4   eth                 909 non-null    int64  \n",
      " 5   baseline            909 non-null    float64\n",
      " 6   PHQ_mean            909 non-null    float64\n",
      " 7   GAD_mean            909 non-null    float64\n",
      " 8   IUS_mean            909 non-null    float64\n",
      " 9   PTSD_mean           909 non-null    float64\n",
      " 10  overallSev          909 non-null    float64\n",
      " 11  txHist_now          909 non-null    int64  \n",
      " 12  txHist_past         909 non-null    int64  \n",
      " 13  txHist_wanted       909 non-null    int64  \n",
      " 14  txHist_neverWanted  909 non-null    int64  \n",
      "dtypes: float64(6), int64(8), object(1)\n",
      "memory usage: 106.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Read Data\n",
    "df = pd.read_csv('../Results/txData_naOmit2.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "living-surgeon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 909 entries, 0 to 908\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   id                  909 non-null    object  \n",
      " 1   age                 909 non-null    int64   \n",
      " 2   gender              909 non-null    category\n",
      " 3   race                909 non-null    category\n",
      " 4   eth                 909 non-null    category\n",
      " 5   baseline            909 non-null    float64 \n",
      " 6   PHQ_mean            909 non-null    float64 \n",
      " 7   GAD_mean            909 non-null    float64 \n",
      " 8   IUS_mean            909 non-null    float64 \n",
      " 9   PTSD_mean           909 non-null    float64 \n",
      " 10  overallSev          909 non-null    float64 \n",
      " 11  txHist_now          909 non-null    category\n",
      " 12  txHist_past         909 non-null    category\n",
      " 13  txHist_wanted       909 non-null    category\n",
      " 14  txHist_neverWanted  909 non-null    category\n",
      "dtypes: category(7), float64(6), int64(1), object(1)\n",
      "memory usage: 64.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>eth</th>\n",
       "      <th>baseline</th>\n",
       "      <th>PHQ_mean</th>\n",
       "      <th>GAD_mean</th>\n",
       "      <th>IUS_mean</th>\n",
       "      <th>PTSD_mean</th>\n",
       "      <th>overallSev</th>\n",
       "      <th>txHist_now</th>\n",
       "      <th>txHist_past</th>\n",
       "      <th>txHist_wanted</th>\n",
       "      <th>txHist_neverWanted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R_0HvLbcWuG0qvY'7</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.281137</td>\n",
       "      <td>-0.436839</td>\n",
       "      <td>-0.392727</td>\n",
       "      <td>0.699956</td>\n",
       "      <td>-1.268364</td>\n",
       "      <td>-0.454732</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R_3CKvhPmYR'BE6wo</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.661865</td>\n",
       "      <td>1.702294</td>\n",
       "      <td>1.018119</td>\n",
       "      <td>1.377332</td>\n",
       "      <td>0.105005</td>\n",
       "      <td>1.347011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_6Du25nbgEoaAQBH</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.661865</td>\n",
       "      <td>0.561423</td>\n",
       "      <td>-0.235966</td>\n",
       "      <td>0.119348</td>\n",
       "      <td>1.478373</td>\n",
       "      <td>0.627447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R_PLs6HbYPMnE4vgl</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.224139</td>\n",
       "      <td>-0.436839</td>\n",
       "      <td>-0.079206</td>\n",
       "      <td>1.474100</td>\n",
       "      <td>1.478373</td>\n",
       "      <td>0.795428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R_1roFlWXv3P94yt6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.661865</td>\n",
       "      <td>-0.579447</td>\n",
       "      <td>-0.549488</td>\n",
       "      <td>-0.364492</td>\n",
       "      <td>-1.268364</td>\n",
       "      <td>-0.893623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  age gender race eth  baseline  PHQ_mean  GAD_mean  \\\n",
       "0  R_0HvLbcWuG0qvY'7   19      2    2   0  0.281137 -0.436839 -0.392727   \n",
       "1  R_3CKvhPmYR'BE6wo   26      2    1   0 -0.661865  1.702294  1.018119   \n",
       "2  R_6Du25nbgEoaAQBH   19      2    1   1 -0.661865  0.561423 -0.235966   \n",
       "3  R_PLs6HbYPMnE4vgl   21      1    6   0  1.224139 -0.436839 -0.079206   \n",
       "4  R_1roFlWXv3P94yt6   19      1    1   0 -0.661865 -0.579447 -0.549488   \n",
       "\n",
       "   IUS_mean  PTSD_mean  overallSev txHist_now txHist_past txHist_wanted  \\\n",
       "0  0.699956  -1.268364   -0.454732          0           1             0   \n",
       "1  1.377332   0.105005    1.347011          1           1             0   \n",
       "2  0.119348   1.478373    0.627447          0           0             1   \n",
       "3  1.474100   1.478373    0.795428          0           0             1   \n",
       "4 -0.364492  -1.268364   -0.893623          0           0             1   \n",
       "\n",
       "  txHist_neverWanted  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify Data Type\n",
    "categoricalVar = ['gender', 'race', 'eth', 'txHist_now', 'txHist_past', 'txHist_wanted', 'txHist_neverWanted']\n",
    "df[categoricalVar] = df[categoricalVar].astype('category')\n",
    "df.info()\n",
    "df.head()\n",
    "#Gender 1 = Men; 2 = Women; 3 = Other specified gender\n",
    "#Race 1 = White, 2 = Black; 4 = Asian; 6 = Other\n",
    "#Eth 0 = Non-Hispanic/Latinx; 1 = Hisapnic/Latinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handy-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardized Continuous Varaibles (exclude age)\n",
    "stdsc = StandardScaler()\n",
    "df[df.select_dtypes(['float']).columns] = stdsc.fit_transform(df.select_dtypes(['float']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "several-labor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define subsets\n",
    "X1 = df[['gender', 'race', 'eth', 'PHQ_mean', 'GAD_mean', 'IUS_mean', 'PTSD_mean']] #Demographic varialbes with four separate interalizing domains\n",
    "X2 = df[['gender', 'race', 'eth', 'overallSev']] #Demographic varialbes with one aggregated overall internalzing severity\n",
    "y = df['txHist_now'].astype('category') #Outcome variable: treatment usage \n",
    "\n",
    "#Split data into training and testing sets\n",
    "n_splits = 10\n",
    "\n",
    "for rnd in range(100):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle = True, random_state=rnd)\n",
    "    i = 0\n",
    "    for train_index, test_index in skf.split(X1, y):\n",
    "        #/print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        locals()[f\"X1_train{rnd}_{i}\"] = X1.iloc[train_index]\n",
    "        locals()[f\"X1_test{rnd}_{i}\"] = X1.iloc[test_index]\n",
    "        locals()[f\"X2_train{rnd}_{i}\"] = X2.iloc[train_index]\n",
    "        locals()[f\"X2_test{rnd}_{i}\"] = X2.iloc[test_index]\n",
    "        locals()[f\"y_train{rnd}_{i}\"] = y.iloc[train_index]\n",
    "        locals()[f\"y_test{rnd}_{i}\"] = y.iloc[test_index]\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accessory-contract",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1(DEM) 0.5993 (0.0565)\n",
      " M2(4INT) 0.5247 (0.0578)\n",
      " M3(1INT) 0.5517 (0.0579)\n",
      " M4(DEM+4INT) 0.5987 (0.0557)\n",
      " M5(DEM+1INT)0.6001 (0.0542)\n",
      " M6(DEM*4INT) 0.5877 (0.0560)\n",
      " M7(DEM*1INT) 0.5842 (0.0551)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Smote sampling for unbalanced class (i.e., most people did not use mental health services)\n",
    "smote = SMOTENC(categorical_features=[0,1,2], random_state=1)\n",
    "\n",
    "#Define preprocessing \n",
    "preprocess1 = Preprocessor(['PHQ_mean','GAD_mean','IUS_mean','PTSD_mean'],\n",
    "                          ['gender','race','eth'])\n",
    "preprocess2 = Preprocessor(['overallSev'],\n",
    "                          ['gender','race','eth'])\n",
    "\n",
    "\n",
    "#Define interaction terms\n",
    "interaction1 = InteractionTerm(['PHQ_mean','GAD_mean','IUS_mean','PTSD_mean'], \n",
    "                                    ['gender_2','gender_3','race_2','race_4','race_6','eth_1'])\n",
    "interaction2 = InteractionTerm(['overallSev'], \n",
    "                                    ['gender_2','gender_3','race_2','race_4','race_6','eth_1'])\n",
    "\n",
    "#Define model\n",
    "model = LogisticRegression(penalty = 'none', max_iter=1000, random_state=1)\n",
    "\n",
    "performanceM1 = [] #Predictors: Demographic Variables\n",
    "performanceM2 = [] #Predictors: 4 Separate Interalizing Domains\n",
    "performanceM3 = [] #Predictors: Aggregate overall internalizing severity \n",
    "performanceM4 = [] #Predictors: Demographic Var. + 4 Separate Interalizing Domains\n",
    "performanceM5 = [] #Predictors: Demographic Var. + Aggregate overall internalizing severity \n",
    "performanceM6 = [] #Predictors: Demographic Var. * 4 Separate Interalizing Domains\n",
    "performanceM7 = [] #Predictors: Demographic Var. * Aggregate overall internalizing severity \n",
    "\n",
    "for rnd in range(100):\n",
    "    for i in range(n_splits):\n",
    "\n",
    "        X1_train = locals()[f\"X1_train{rnd}_{i}\"]\n",
    "        X2_train = locals()[f\"X2_train{rnd}_{i}\"]\n",
    "        y_train = locals()[f\"y_train{rnd}_{i}\"]\n",
    "        X1_test = locals()[f\"X1_test{rnd}_{i}\"]\n",
    "        X2_test = locals()[f\"X2_test{rnd}_{i}\"]\n",
    "        y_test = locals()[f\"y_test{rnd}_{i}\"]\n",
    "\n",
    "        X1_test_pre = preprocess1.fit_transform(X1_test)\n",
    "        X2_test_pre = preprocess2.fit_transform(X2_test)\n",
    "\n",
    "        X1_test_pre_int = interaction1.fit_transform(X1_test_pre)\n",
    "        X2_test_pre_int = interaction2.fit_transform(X2_test_pre)\n",
    "\n",
    "        X1_train_sm, y_train_sm = smote.fit_resample(X1_train, y_train)\n",
    "        X2_train_sm, y_train_sm = smote.fit_resample(X2_train, y_train)\n",
    "\n",
    "        X1_train_sm_pre = preprocess1.fit_transform(X1_train_sm)\n",
    "        X2_train_sm_pre = preprocess2.fit_transform(X2_train_sm)\n",
    "\n",
    "        X1_train_sm_pre_int = interaction1.fit_transform(X1_train_sm_pre)\n",
    "        X2_train_sm_pre_int = interaction2.fit_transform(X2_train_sm_pre)\n",
    "\n",
    "        predM1 = model.fit(X1_train_sm_pre[['gender_2','gender_3','race_2','race_4','race_6','eth_1']], \n",
    "                          y_train_sm).predict(X1_test_pre[['gender_2','gender_3','race_2','race_4','race_6','eth_1']])\n",
    "        predM2 = model.fit(X1_train_sm_pre[['PHQ_mean','GAD_mean','IUS_mean','PTSD_mean']], \n",
    "                          y_train_sm).predict(X1_test_pre[['PHQ_mean','GAD_mean','IUS_mean','PTSD_mean']])\n",
    "        predM3 = model.fit(X2_train_sm_pre[['overallSev']], y_train_sm).predict(X2_test_pre[['overallSev']])\n",
    "\n",
    "        predM4 = model.fit(X1_train_sm_pre, y_train_sm).predict(X1_test_pre)\n",
    "        predM5 = model.fit(X2_train_sm_pre, y_train_sm).predict(X2_test_pre)\n",
    "        predM6 = model.fit(X1_train_sm_pre_int, y_train_sm).predict(X1_test_pre_int)\n",
    "        predM7 = model.fit(X2_train_sm_pre_int, y_train_sm).predict(X2_test_pre_int)\n",
    "\n",
    "        performanceM1.append(balanced_accuracy_score(y_test, predM1))\n",
    "        performanceM2.append(balanced_accuracy_score(y_test, predM2))\n",
    "        performanceM3.append(balanced_accuracy_score(y_test, predM3))\n",
    "        performanceM4.append(balanced_accuracy_score(y_test, predM4))\n",
    "        performanceM5.append(balanced_accuracy_score(y_test, predM5))\n",
    "        performanceM6.append(balanced_accuracy_score(y_test, predM6))\n",
    "        performanceM7.append(balanced_accuracy_score(y_test, predM7))\n",
    "\n",
    "print(\n",
    "      \"M1(DEM) %.4f\" % mean(performanceM1), \"(%.4f)\\n\" % std(performanceM1),\n",
    "      \"M2(4INT) %.4f\" % mean(performanceM2), \"(%.4f)\\n\" % std(performanceM2),\n",
    "      \"M3(1INT) %.4f\" % mean(performanceM3), \"(%.4f)\\n\" % std(performanceM3),\n",
    "      \"M4(DEM+4INT) %.4f\" % mean(performanceM4), \"(%.4f)\\n\" % std(performanceM4),\n",
    "      \"M5(DEM+1INT)%.4f\" % mean(performanceM5), \"(%.4f)\\n\" % std(performanceM5),\n",
    "      \"M6(DEM*4INT) %.4f\" % mean(performanceM6), \"(%.4f)\\n\" % std(performanceM6),\n",
    "      \"M7(DEM*1INT) %.4f\" % mean(performanceM7), \"(%.4f)\\n\" % std(performanceM7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "corporate-replica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=55.49889925139725, pvalue=1.851379041187304e-307)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#T-tests comparing M1 to chance level\n",
    "ttest_1samp(performanceM1, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-copyright",
   "metadata": {},
   "source": [
    "The result indicates that M1 performed better than chance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "english-floor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "T-tests comparing M1(DEM) and M5(DEM+1INT)\n",
      "Ttest_indResult(statistic=-0.3315007612411852, pvalue=0.740301032304172)\n"
     ]
    }
   ],
   "source": [
    "print('\\nT-tests comparing M1(DEM) and M5(DEM+1INT)')\n",
    "print(ttest_ind(performanceM1, performanceM5)) \n",
    "##The additional main effect of aggreagtted internlizing severity did not significantly improve predication accuracy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-academy",
   "metadata": {},
   "source": [
    "Overall, the results indicate demographcs factors are more robust predictors of mental health treatment use than internalizing psychiatirc problems, such as depression, anxiety, PTSD, and intolerance of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-drain",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-production",
   "metadata": {},
   "source": [
    "According to the results above, the final model is the model using demographic variables to predict mental health services use without considering psychiatric symptom severity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alert-compact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.01011608, -0.5285973 , -1.42999059, -2.38112951, -1.86203444,\n",
       "        -1.40157919]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = model.fit(X1_train_sm_pre[['gender_2','gender_3','race_2','race_4','race_6','eth_1']], \n",
    "                          y_train_sm)\n",
    "final_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-scientist",
   "metadata": {},
   "source": [
    "According to the coeeficients, women (gender_2) showed higher odds in using mental health services than men.  \n",
    "Other-specified gender (gender_3) showed lower odds in using mental health services than men.\n",
    "\n",
    "People of color (race_2: Black, race_4: Asian; race_6: Others, eth_1: Hispanic/Latinx) showed lower odds in using mental heatlh services than White. Furhter, the Asian American population has the lowest mental heatlh services use rate compared to other racial/ethnic groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "collect-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save SMOTE smple data for outer use \n",
    "smote = SMOTENC(categorical_features=[0,1,2], random_state=1)\n",
    "X2_sm, y_sm = smote.fit_resample(X2, y)\n",
    "data4Glm = X2_sm\n",
    "data4Glm['txHist_now'] = y_sm\n",
    "data4Glm.to_csv('../Data/data4Glm.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
